{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd.function import Function\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from itertools import chain\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import itertools\n",
    "import random\n",
    "import tqdm\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.fft import fftshift\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "from torch import nn, einsum\n",
    "import math\n",
    "import logging\n",
    "from functools import partial\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import classification_report\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Aug 10 21:57:51 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:01:00.0 Off |                  N/A |\r\n",
      "| 39%   35C    P8    35W / 260W |  10906MiB / 11016MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A     57080      C   /opt/anaconda3/bin/python       10903MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA System Management Interface -- v460.91.03\r\n",
      "\r\n",
      "NVSMI provides monitoring information for Tesla and select Quadro devices.\r\n",
      "The data is presented in either a plain text or an XML format, via stdout or a file.\r\n",
      "NVSMI also provides several management operations for changing the device state.\r\n",
      "\r\n",
      "Note that the functionality of NVSMI is exposed through the NVML C-based\r\n",
      "library. See the NVIDIA developer website for more information about NVML.\r\n",
      "Python wrappers to NVML are also available.  The output of NVSMI is\r\n",
      "not guaranteed to be backwards compatible; NVML and the bindings are backwards\r\n",
      "compatible.\r\n",
      "\r\n",
      "http://developer.nvidia.com/nvidia-management-library-nvml/\r\n",
      "http://pypi.python.org/pypi/nvidia-ml-py/\r\n",
      "Supported products:\r\n",
      "- Full Support\r\n",
      "    - All Tesla products, starting with the Kepler architecture\r\n",
      "    - All Quadro products, starting with the Kepler architecture\r\n",
      "    - All GRID products, starting with the Kepler architecture\r\n",
      "    - GeForce Titan products, starting with the Kepler architecture\r\n",
      "- Limited Support\r\n",
      "    - All Geforce products, starting with the Kepler architecture\r\n",
      "nvidia-smi [OPTION1 [ARG1]] [OPTION2 [ARG2]] ...\r\n",
      "\r\n",
      "    -h,   --help                Print usage information and exit.\r\n",
      "\r\n",
      "  LIST OPTIONS:\r\n",
      "\r\n",
      "    -L,   --list-gpus           Display a list of GPUs connected to the system.\r\n",
      "\r\n",
      "    -B,   --list-blacklist-gpus Display a list of blacklisted GPUs in the system.\r\n",
      "\r\n",
      "  SUMMARY OPTIONS:\r\n",
      "\r\n",
      "    <no arguments>              Show a summary of GPUs connected to the system.\r\n",
      "\r\n",
      "    [plus any of]\r\n",
      "\r\n",
      "    -i,   --id=                 Target a specific GPU.\r\n",
      "    -f,   --filename=           Log to a specified file, rather than to stdout.\r\n",
      "    -l,   --loop=               Probe until Ctrl+C at specified second interval.\r\n",
      "\r\n",
      "  QUERY OPTIONS:\r\n",
      "\r\n",
      "    -q,   --query               Display GPU or Unit info.\r\n",
      "\r\n",
      "    [plus any of]\r\n",
      "\r\n",
      "    -u,   --unit                Show unit, rather than GPU, attributes.\r\n",
      "    -i,   --id=                 Target a specific GPU or Unit.\r\n",
      "    -f,   --filename=           Log to a specified file, rather than to stdout.\r\n",
      "    -x,   --xml-format          Produce XML output.\r\n",
      "          --dtd                 When showing xml output, embed DTD.\r\n",
      "    -d,   --display=            Display only selected information: MEMORY,\r\n",
      "                                    UTILIZATION, ECC, TEMPERATURE, POWER, CLOCK,\r\n",
      "                                    COMPUTE, PIDS, PERFORMANCE, SUPPORTED_CLOCKS,\r\n",
      "                                    PAGE_RETIREMENT, ACCOUNTING, ENCODER_STATS,\r\n",
      "                                    SUPPORTED_GPU_TARGET_TEMP\r\n",
      "                                    FBC_STATS, ROW_REMAPPER\r\n",
      "                                Flags can be combined with comma e.g. ECC,POWER.\r\n",
      "                                Sampling data with max/min/avg is also returned \r\n",
      "                                for POWER, UTILIZATION and CLOCK display types.\r\n",
      "                                Doesn't work with -u or -x flags.\r\n",
      "    -l,   --loop=               Probe until Ctrl+C at specified second interval.\r\n",
      "\r\n",
      "    -lms, --loop-ms=            Probe until Ctrl+C at specified millisecond interval.\r\n",
      "\r\n",
      "  SELECTIVE QUERY OPTIONS:\r\n",
      "\r\n",
      "    Allows the caller to pass an explicit list of properties to query.\r\n",
      "\r\n",
      "    [one of]\r\n",
      "\r\n",
      "    --query-gpu=                Information about GPU.\r\n",
      "                                Call --help-query-gpu for more info.\r\n",
      "    --query-supported-clocks=   List of supported clocks.\r\n",
      "                                Call --help-query-supported-clocks for more info.\r\n",
      "    --query-compute-apps=       List of currently active compute processes.\r\n",
      "                                Call --help-query-compute-apps for more info.\r\n",
      "    --query-accounted-apps=     List of accounted compute processes.\r\n",
      "                                Call --help-query-accounted-apps for more info.\r\n",
      "                                This query is not supported on vGPU host.\r\n",
      "    --query-retired-pages=      List of device memory pages that have been retired.\r\n",
      "                                Call --help-query-retired-pages for more info.\r\n",
      "    --query-remapped-rows=      Information about remapped rows.\r\n",
      "                                Call --help-query-remapped-rows for more info.\r\n",
      "\r\n",
      "    [mandatory]\r\n",
      "\r\n",
      "    --format=                   Comma separated list of format options:\r\n",
      "                                  csv - comma separated values (MANDATORY)\r\n",
      "                                  noheader - skip the first line with column headers\r\n",
      "                                  nounits - don't print units for numerical\r\n",
      "                                             values\r\n",
      "\r\n",
      "    [plus any of]\r\n",
      "\r\n",
      "    -i,   --id=                 Target a specific GPU or Unit.\r\n",
      "    -f,   --filename=           Log to a specified file, rather than to stdout.\r\n",
      "    -l,   --loop=               Probe until Ctrl+C at specified second interval.\r\n",
      "    -lms, --loop-ms=            Probe until Ctrl+C at specified millisecond interval.\r\n",
      "\r\n",
      "  DEVICE MODIFICATION OPTIONS:\r\n",
      "\r\n",
      "    [any one of]\r\n",
      "\r\n",
      "    -pm,  --persistence-mode=   Set persistence mode: 0/DISABLED, 1/ENABLED\r\n",
      "    -e,   --ecc-config=         Toggle ECC support: 0/DISABLED, 1/ENABLED\r\n",
      "    -p,   --reset-ecc-errors=   Reset ECC error counts: 0/VOLATILE, 1/AGGREGATE\r\n",
      "    -c,   --compute-mode=       Set MODE for compute applications:\r\n",
      "                                0/DEFAULT, 1/EXCLUSIVE_PROCESS,\r\n",
      "                                2/PROHIBITED\r\n",
      "          --gom=                Set GPU Operation Mode:\r\n",
      "                                    0/ALL_ON, 1/COMPUTE, 2/LOW_DP\r\n",
      "    -r    --gpu-reset           Trigger reset of the GPU.\r\n",
      "                                Can be used to reset the GPU HW state in situations\r\n",
      "                                that would otherwise require a machine reboot.\r\n",
      "                                Typically useful if a double bit ECC error has\r\n",
      "                                occurred.\r\n",
      "                                Reset operations are not guarenteed to work in\r\n",
      "                                all cases and should be used with caution.\r\n",
      "    -vm   --virt-mode=          Switch GPU Virtualization Mode:\r\n",
      "                                Sets GPU virtualization mode to 3/VGPU or 4/VSGA\r\n",
      "                                Virtualization mode of a GPU can only be set when\r\n",
      "                                it is running on a hypervisor.\r\n",
      "    -lgc  --lock-gpu-clocks=    Specifies <minGpuClock,maxGpuClock> clocks as a\r\n",
      "                                    pair (e.g. 1500,1500) that defines the range \r\n",
      "                                    of desired locked GPU clock speed in MHz.\r\n",
      "                                    Setting this will supercede application clocks\r\n",
      "                                    and take effect regardless if an app is running.\r\n",
      "                                    Input can also be a singular desired clock value\r\n",
      "                                    (e.g. <GpuClockValue>).\r\n",
      "    -rgc  --reset-gpu-clocks\r\n",
      "                                Resets the Gpu clocks to the default values.\r\n",
      "    -ac   --applications-clocks= Specifies <memory,graphics> clocks as a\r\n",
      "                                    pair (e.g. 2000,800) that defines GPU's\r\n",
      "                                    speed in MHz while running applications on a GPU.\r\n",
      "    -rac  --reset-applications-clocks\r\n",
      "                                Resets the applications clocks to the default values.\r\n",
      "    -acp  --applications-clocks-permission=\r\n",
      "                                Toggles permission requirements for -ac and -rac commands:\r\n",
      "                                0/UNRESTRICTED, 1/RESTRICTED\r\n",
      "    -pl   --power-limit=        Specifies maximum power management limit in watts.\r\n",
      "    -cc   --cuda-clocks=        Overrides or restores default CUDA clocks.\r\n",
      "                                In override mode, GPU clocks higher frequencies when running CUDA applications.\r\n",
      "                                Only on supported devices starting from the Volta series.\r\n",
      "                                Requires administrator privileges.\r\n",
      "                                0/RESTORE_DEFAULT, 1/OVERRIDE\r\n",
      "    -am   --accounting-mode=    Enable or disable Accounting Mode: 0/DISABLED, 1/ENABLED\r\n",
      "    -caa  --clear-accounted-apps\r\n",
      "                                Clears all the accounted PIDs in the buffer.\r\n",
      "          --auto-boost-default= Set the default auto boost policy to 0/DISABLED\r\n",
      "                                or 1/ENABLED, enforcing the change only after the\r\n",
      "                                last boost client has exited.\r\n",
      "          --auto-boost-permission=\r\n",
      "                                Allow non-admin/root control over auto boost mode:\r\n",
      "                                0/UNRESTRICTED, 1/RESTRICTED\r\n",
      "    -mig  --multi-instance-gpu= Enable or disable Multi Instance GPU: 0/DISABLED, 1/ENABLED\r\n",
      "                                Requires root.\r\n",
      "    -gtt  --gpu-target-temp=    Set GPU Target Temperature for a GPU in degree celsius.\r\n",
      "                                Requires administrator privileges\r\n",
      "\r\n",
      "   [plus optional]\r\n",
      "\r\n",
      "    -i,   --id=                 Target a specific GPU.\r\n",
      "    -eow, --error-on-warning    Return a non-zero error for warnings.\r\n",
      "\r\n",
      "  UNIT MODIFICATION OPTIONS:\r\n",
      "\r\n",
      "    -t,   --toggle-led=         Set Unit LED state: 0/GREEN, 1/AMBER\r\n",
      "\r\n",
      "   [plus optional]\r\n",
      "\r\n",
      "    -i,   --id=                 Target a specific Unit.\r\n",
      "\r\n",
      "  SHOW DTD OPTIONS:\r\n",
      "\r\n",
      "          --dtd                 Print device DTD and exit.\r\n",
      "\r\n",
      "     [plus optional]\r\n",
      "\r\n",
      "    -f,   --filename=           Log to a specified file, rather than to stdout.\r\n",
      "    -u,   --unit                Show unit, rather than device, DTD.\r\n",
      "\r\n",
      "    --debug=                    Log encrypted debug information to a specified file. \r\n",
      "\r\n",
      " STATISTICS: (EXPERIMENTAL)\r\n",
      "    stats                       Displays device statistics. \"nvidia-smi stats -h\" for more information.\r\n",
      "\r\n",
      " Device Monitoring:\r\n",
      "    dmon                        Displays device stats in scrolling format.\r\n",
      "                                \"nvidia-smi dmon -h\" for more information.\r\n",
      "\r\n",
      "    daemon                      Runs in background and monitor devices as a daemon process.\r\n",
      "                                This is an experimental feature. Not supported on Windows baremetal\r\n",
      "                                \"nvidia-smi daemon -h\" for more information.\r\n",
      "\r\n",
      "    replay                      Used to replay/extract the persistent stats generated by daemon.\r\n",
      "                                This is an experimental feature.\r\n",
      "                                \"nvidia-smi replay -h\" for more information.\r\n",
      "\r\n",
      " Process Monitoring:\r\n",
      "    pmon                        Displays process stats in scrolling format.\r\n",
      "                                \"nvidia-smi pmon -h\" for more information.\r\n",
      "\r\n",
      " TOPOLOGY:\r\n",
      "    topo                        Displays device/system topology. \"nvidia-smi topo -h\" for more information.\r\n",
      "\r\n",
      " DRAIN STATES:\r\n",
      "    drain                       Displays/modifies GPU drain states for power idling. \"nvidia-smi drain -h\" for more information.\r\n",
      "\r\n",
      " NVLINK:\r\n",
      "    nvlink                      Displays device nvlink information. \"nvidia-smi nvlink -h\" for more information.\r\n",
      "\r\n",
      " CLOCKS:\r\n",
      "    clocks                      Control and query clock information. \"nvidia-smi clocks -h\" for more information.\r\n",
      "\r\n",
      " ENCODER SESSIONS:\r\n",
      "    encodersessions             Displays device encoder sessions information. \"nvidia-smi encodersessions -h\" for more information.\r\n",
      "\r\n",
      " FBC SESSIONS:\r\n",
      "    fbcsessions                 Displays device FBC sessions information. \"nvidia-smi fbcsessions -h\" for more information.\r\n",
      "\r\n",
      " GRID vGPU:\r\n",
      "    vgpu                        Displays vGPU information. \"nvidia-smi vgpu -h\" for more information.\r\n",
      "\r\n",
      " MIG:\r\n",
      "    mig                         Provides controls for MIG management. \"nvidia-smi mig -h\" for more information.\r\n",
      "\r\n",
      " COMPUTE POLICY:\r\n",
      "    compute-policy              Control and query compute policies. \"nvidia-smi compute-policy -h\" for more information. \r\n",
      "\r\n",
      " BOOST SLIDER:\r\n",
      "    boost-slider                Control and query boost sliders. \"nvidia-smi boost-slider -h\" for more information. \r\n",
      "\r\n",
      "Please see the nvidia-smi(1) manual page for more detailed information.\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============NVSMI LOG==============\n",
      "\n",
      "Timestamp                                 : Tue Aug 10 20:29:31 2021\n",
      "Driver Version                            : 460.91.03\n",
      "CUDA Version                              : 11.2\n",
      "\n",
      "Attached GPUs                             : 1\n",
      "GPU 00000000:01:00.0\n",
      "    Product Name                          : GeForce RTX 2080 Ti\n",
      "    Product Brand                         : GeForce\n",
      "    Display Mode                          : Enabled\n",
      "    Display Active                        : Disabled\n",
      "    Persistence Mode                      : Disabled\n",
      "    MIG Mode\n",
      "        Current                           : N/A\n",
      "        Pending                           : N/A\n",
      "    Accounting Mode                       : Disabled\n",
      "    Accounting Mode Buffer Size           : 4000\n",
      "    Driver Model\n",
      "        Current                           : N/A\n",
      "        Pending                           : N/A\n",
      "    Serial Number                         : N/A\n",
      "    GPU UUID                              : GPU-194e9f2f-a2f6-9b45-eb16-037cfb8b02e1\n",
      "    Minor Number                          : 0\n",
      "    VBIOS Version                         : 90.02.17.00.58\n",
      "    MultiGPU Board                        : No\n",
      "    Board ID                              : 0x100\n",
      "    GPU Part Number                       : N/A\n",
      "    Inforom Version\n",
      "        Image Version                     : G001.0000.02.04\n",
      "        OEM Object                        : 1.1\n",
      "        ECC Object                        : N/A\n",
      "        Power Management Object           : N/A\n",
      "    GPU Operation Mode\n",
      "        Current                           : N/A\n",
      "        Pending                           : N/A\n",
      "    GPU Virtualization Mode\n",
      "        Virtualization Mode               : None\n",
      "        Host VGPU Mode                    : N/A\n",
      "    IBMNPU\n",
      "        Relaxed Ordering Mode             : N/A\n",
      "    PCI\n",
      "        Bus                               : 0x01\n",
      "        Device                            : 0x00\n",
      "        Domain                            : 0x0000\n",
      "        Device Id                         : 0x1E0710DE\n",
      "        Bus Id                            : 00000000:01:00.0\n",
      "        Sub System Id                     : 0x150319DA\n",
      "        GPU Link Info\n",
      "            PCIe Generation\n",
      "                Max                       : 3\n",
      "                Current                   : 3\n",
      "            Link Width\n",
      "                Max                       : 16x\n",
      "                Current                   : 16x\n",
      "        Bridge Chip\n",
      "            Type                          : N/A\n",
      "            Firmware                      : N/A\n",
      "        Replays Since Reset               : 0\n",
      "        Replay Number Rollovers           : 0\n",
      "        Tx Throughput                     : 6000 KB/s\n",
      "        Rx Throughput                     : 100000 KB/s\n",
      "    Fan Speed                             : 49 %\n",
      "    Performance State                     : P2\n",
      "    Clocks Throttle Reasons\n",
      "        Idle                              : Not Active\n",
      "        Applications Clocks Setting       : Not Active\n",
      "        SW Power Cap                      : Active\n",
      "        HW Slowdown                       : Not Active\n",
      "            HW Thermal Slowdown           : Not Active\n",
      "            HW Power Brake Slowdown       : Not Active\n",
      "        Sync Boost                        : Not Active\n",
      "        SW Thermal Slowdown               : Not Active\n",
      "        Display Clock Setting             : Not Active\n",
      "    FB Memory Usage\n",
      "        Total                             : 11016 MiB\n",
      "        Used                              : 3084 MiB\n",
      "        Free                              : 7932 MiB\n",
      "    BAR1 Memory Usage\n",
      "        Total                             : 256 MiB\n",
      "        Used                              : 10 MiB\n",
      "        Free                              : 246 MiB\n",
      "    Compute Mode                          : Default\n",
      "    Utilization\n",
      "        Gpu                               : 96 %\n",
      "        Memory                            : 64 %\n",
      "        Encoder                           : 0 %\n",
      "        Decoder                           : 0 %\n",
      "    Encoder Stats\n",
      "        Active Sessions                   : 0\n",
      "        Average FPS                       : 0\n",
      "        Average Latency                   : 0\n",
      "    FBC Stats\n",
      "        Active Sessions                   : 0\n",
      "        Average FPS                       : 0\n",
      "        Average Latency                   : 0\n",
      "    Ecc Mode\n",
      "        Current                           : N/A\n",
      "        Pending                           : N/A\n",
      "    ECC Errors\n",
      "        Volatile\n",
      "            SRAM Correctable              : N/A\n",
      "            SRAM Uncorrectable            : N/A\n",
      "            DRAM Correctable              : N/A\n",
      "            DRAM Uncorrectable            : N/A\n",
      "        Aggregate\n",
      "            SRAM Correctable              : N/A\n",
      "            SRAM Uncorrectable            : N/A\n",
      "            DRAM Correctable              : N/A\n",
      "            DRAM Uncorrectable            : N/A\n",
      "    Retired Pages\n",
      "        Single Bit ECC                    : N/A\n",
      "        Double Bit ECC                    : N/A\n",
      "        Pending Page Blacklist            : N/A\n",
      "    Remapped Rows                         : N/A\n",
      "    Temperature\n",
      "        GPU Current Temp                  : 56 C\n",
      "        GPU Shutdown Temp                 : 94 C\n",
      "        GPU Slowdown Temp                 : 91 C\n",
      "        GPU Max Operating Temp            : 89 C\n",
      "        GPU Target Temperature            : 84 C\n",
      "        Memory Current Temp               : N/A\n",
      "        Memory Max Operating Temp         : N/A\n",
      "    Power Readings\n",
      "        Power Management                  : Supported\n",
      "        Power Draw                        : 255.60 W\n",
      "        Power Limit                       : 260.00 W\n",
      "        Default Power Limit               : 260.00 W\n",
      "        Enforced Power Limit              : 260.00 W\n",
      "        Min Power Limit                   : 100.00 W\n",
      "        Max Power Limit                   : 300.00 W\n",
      "    Clocks\n",
      "        Graphics                          : 1920 MHz\n",
      "        SM                                : 1920 MHz\n",
      "        Memory                            : 6800 MHz\n",
      "        Video                             : 1785 MHz\n",
      "    Applications Clocks\n",
      "        Graphics                          : N/A\n",
      "        Memory                            : N/A\n",
      "    Default Applications Clocks\n",
      "        Graphics                          : N/A\n",
      "        Memory                            : N/A\n",
      "    Max Clocks\n",
      "        Graphics                          : 2160 MHz\n",
      "        SM                                : 2160 MHz\n",
      "        Memory                            : 7000 MHz\n",
      "        Video                             : 1950 MHz\n",
      "    Max Customer Boost Clocks\n",
      "        Graphics                          : N/A\n",
      "    Clock Policy\n",
      "        Auto Boost                        : N/A\n",
      "        Auto Boost Default                : N/A\n",
      "    Processes\n",
      "        GPU instance ID                   : N/A\n",
      "        Compute instance ID               : N/A\n",
      "        Process ID                        : 57080\n",
      "            Type                          : C\n",
      "            Name                          : /opt/anaconda3/bin/python\n",
      "            Used GPU Memory               : 3081 MiB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/is/zheng-ch/Transformer/PreTdat\n"
     ]
    }
   ],
   "source": [
    "cd PreTdat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(786606, 32, 30)\n",
      "(786606, 32, 30)\n",
      "(786606, 2, 32, 30)\n"
     ]
    }
   ],
   "source": [
    "dat1 = np.load('/project/hikaku_db/data/sleep_SHHS/stages_sig/C3_spec_30_np/spec_c3_5007_5793_30.npy')\n",
    "dat2 = np.load('/project/hikaku_db/data/sleep_SHHS/stages_sig/C4_spec_30_np/spec_5007_5793_30.npy')\n",
    "print(dat1.shape)\n",
    "print(dat2.shape)\n",
    "\n",
    "dat = np.concatenate((dat1.reshape(-1,1,32,30), dat2.reshape(-1,1,32,30)), axis=1)\n",
    "print(dat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "datgradient = dat[0:10000]\n",
    "np.save('/home/is/zheng-ch/Transformer/PreTdat/testgradientdat', datgradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0\n",
      "2  317703\n",
      "0  220808\n",
      "4  118212\n",
      "3   97754\n",
      "1   32129\n",
      "786606\n"
     ]
    }
   ],
   "source": [
    "index = pd.read_csv(\"/project/hikaku_db/data/sleep_SHHS/stages_sig/ann_delrecords_5class.csv\", header=None)\n",
    "index = index.astype(int)\n",
    "print(index[5007610:5794216].apply(pd.value_counts))\n",
    "label = index[5007610:5794216].values.tolist()#list\n",
    "print(len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "listgradient = np.array(label[0:10000])\n",
    "np.save('/home/is/zheng-ch/Transformer/PreTdat/testgradientdat_label', listgradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "####start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = np.load('testgradientdat.npy')\n",
    "label = np.load('testgradientdat_lable.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mydatasets(torch.utils.data.Dataset):\n",
    "    def __init__(self, data,label ,transform = None):\n",
    "        self.transform = transform\n",
    "\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "\n",
    "        self.datanum = len(data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.datanum\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        out_data = torch.tensor(self.data[idx]).float()\n",
    "        out_label = torch.tensor(self.label[idx])\n",
    "        if self.transform:\n",
    "            out_data = self.transform(out_data)\n",
    "\n",
    "        return out_data, out_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(786606, 2, 32, 30)\n",
      "786606\n",
      "(786606, 2, 20, 30)\n",
      "train data: 707945\n",
      "test data: 78661\n"
     ]
    }
   ],
   "source": [
    "print(dat.shape)\n",
    "# label = index[0:100].values.tolist()#list\n",
    "print(len(label))\n",
    "fixdata = dat[:,:,0:16,:]\n",
    "mean_p1 = np.mean(dat[:,:,16:20,:], axis = 2)\n",
    "mean_p2 = np.mean(dat[:,:,20:24,:], axis = 2)\n",
    "mean_p3 = np.mean(dat[:,:,24:28,:], axis = 2)\n",
    "mean_p4 = np.mean(dat[:,:,28:32,:], axis = 2)\n",
    "num_data = len(dat)\n",
    "ch = 2\n",
    "inputdat = np.concatenate((fixdata,mean_p1.reshape(num_data, ch, 1, 30),mean_p2.reshape(num_data, ch, 1, 30),mean_p3.reshape(num_data, ch, 1, 30),mean_p4.reshape(num_data, ch, 1, 30)),axis=2)\n",
    "print(inputdat.shape)\n",
    "\n",
    "train, test, train_label, test_label = train_test_split(inputdat, np.array(label),test_size = 0.1, stratify = label,random_state = 0)\n",
    "print('train data:',len(train))\n",
    "print('test data:',len(test))\n",
    "\n",
    "train_data_set = Mydatasets(data=train,label=train_label)\n",
    "test_data_set = Mydatasets(data=test,label=test_label)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_data_set, batch_size = 64, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data_set, batch_size = 64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Transformer model, flatted the EEG channel, allows parallel computation the multi-band from multi-channel. \n",
    "\n",
    "class PreNorm(nn.Module): \n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(self.norm(x), **kwargs)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout = 0.5):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads, dim_head, dropout = 0.5):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head *  heads       ##32(4*8)   \n",
    "        project_out = not (heads == 1 and dim_head == dim)\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.attend = nn.Softmax(dim = -1)\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)   ##better to dim to dim*3\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        ) if project_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, n, _, h = *x.shape, self.heads\n",
    "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = h), qkv)\n",
    "\n",
    "        dots = einsum('b h i d, b h j d -> b h i j', q, k) * self.scale\n",
    "\n",
    "        attn = self.attend(dots)\n",
    "\n",
    "        out = einsum('b h i j, b h j d -> b h i d', attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        return self.to_out(out)\n",
    "\n",
    "class Transformer(nn.Module):           ##Register the blocks into whole network\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout = 0.5):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                PreNorm(dim, Attention(dim, heads = heads, dim_head = dim_head, dropout = dropout)),\n",
    "                PreNorm(dim, FeedForward(dim, mlp_dim, dropout = dropout))\n",
    "            ]))\n",
    "    def forward(self, x):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x) + x\n",
    "            x = ff(x) + x\n",
    "        return x\n",
    "\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, *, image_size, time_size, fre_size, num_classes, dim, depth, heads, mlp_dim, pool = 'cls', channels , dim_head, dropout = 0.5, emb_dropout = 0.):\n",
    "        super().__init__()\n",
    "        assert image_size == 30  ##Time dimensions must equal to 30s\n",
    "        num_patches = 300       #30*5'\n",
    "        patch_dim = time_size * fre_size    #1*4'\n",
    "        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n",
    "\n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            Rearrange('b c (h p1) (w p2) -> b (h w c) (p1 p2)', p1 = fre_size, p2 = time_size),\n",
    "            nn.Linear(patch_dim, dim),        ##4 to dim\n",
    "        )\n",
    "\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim)) ##Generate the pos value'\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))                ##Generate the class value'\n",
    "        self.dropout = nn.Dropout(emb_dropout)\n",
    "\n",
    "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n",
    "\n",
    "        self.pool = pool\n",
    "        self.to_latent = nn.Identity()\n",
    "\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = self.to_patch_embedding(img)\n",
    "        b, n, _ = x.shape\n",
    "\n",
    "        cls_tokens = repeat(self.cls_token, '() n d -> b n d', b = b)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x += self.pos_embedding[:, :(n + 1)]\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        x = x.mean(dim = 1) if self.pool == 'mean' else x[:, 0]\n",
    "\n",
    "        x = self.to_latent(x)\n",
    "        return self.mlp_head(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "\n",
    "Transmodel = ViT(\n",
    "    image_size = 30, \n",
    "    time_size = 1, \n",
    "    fre_size = 4, \n",
    "    num_classes = 5, \n",
    "    dim = 32, \n",
    "    depth = 8, \n",
    "    heads = 4, \n",
    "    mlp_dim = 128, \n",
    "    channels = 2,\n",
    "    dim_head = 16\n",
    ").to(DEVICE)\n",
    "\n",
    "#summary(Transmodel,(2286886, 20, 30))\n",
    "\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.AdamW(Transmodel.parameters(), lr=1e-3)\n",
    "\n",
    "#Transmodel.load_state_dict(torch.load('PreTrained_t_Trans_8lay_50drop_mulchan_eegspec_stateTrain'))\n",
    "Transmodel.load_state_dict(torch.load('PreTest_Trans_8lay_50drop_noW_eegspec_state6'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/150 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 :finished\n",
      "train_loss: 0.4326145324153552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:40: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  1%|          | 1/150 [10:50<26:54:31, 650.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.41967308530962566\n",
      "{'0': {'precision': 0.9201257575067208, 'recall': 0.9145419138625968, 'f1-score': 0.9173253384210048, 'support': 22081}, '1': {'precision': 0.4037940379403794, 'recall': 0.18549642079053844, 'f1-score': 0.25421198549797397, 'support': 3213}, '2': {'precision': 0.8494851605087825, 'recall': 0.8828806143967769, 'f1-score': 0.8658609992128536, 'support': 31771}, '3': {'precision': 0.8826675398384632, 'recall': 0.8273145780051151, 'f1-score': 0.8540951576279242, 'support': 9775}, '4': {'precision': 0.737515318627451, 'recall': 0.8145672954910752, 'f1-score': 0.7741287132692849, 'support': 11821}, 'accuracy': 0.8461117961887085, 'macro avg': {'precision': 0.7587175628843594, 'recall': 0.7249601645092205, 'f1-score': 0.7331244388058084, 'support': 78661}, 'weighted avg': {'precision': 0.8384068841401575, 'recall': 0.8461117961887085, 'f1-score': 0.8400766504168514, 'support': 78661}}\n",
      "epoch 2 :finished\n",
      "train_loss: 0.416430532114617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏         | 2/150 [21:41<26:44:38, 650.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.41301476605297105\n",
      "{'0': {'precision': 0.9224350205198358, 'recall': 0.9161269870024003, 'f1-score': 0.9192701824543863, 'support': 22081}, '1': {'precision': 0.4143884892086331, 'recall': 0.1792717086834734, 'f1-score': 0.25027156202476647, 'support': 3213}, '2': {'precision': 0.8326860653837236, 'recall': 0.9043152560511158, 'f1-score': 0.8670237646171256, 'support': 31771}, '3': {'precision': 0.8914728682170543, 'recall': 0.8117647058823529, 'f1-score': 0.8497536945812808, 'support': 9775}, '4': {'precision': 0.7754691689008043, 'recall': 0.78301328144827, 'f1-score': 0.7792229658626931, 'support': 11821}, 'accuracy': 0.8482856815957082, 'macro avg': {'precision': 0.7672903224460101, 'recall': 0.7188983878135224, 'f1-score': 0.7331084339080505, 'support': 78661}, 'weighted avg': {'precision': 0.8395005812236079, 'recall': 0.8482856815957082, 'f1-score': 0.8411573269753307, 'support': 78661}}\n",
      "epoch 3 :finished\n",
      "train_loss: 0.4105407764434362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 3/150 [32:32<26:33:52, 650.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.40348839698041356\n",
      "{'0': {'precision': 0.9100550230741924, 'recall': 0.9288075721208279, 'f1-score': 0.9193356792254075, 'support': 22081}, '1': {'precision': 0.4261414503133393, 'recall': 0.14814814814814814, 'f1-score': 0.21986143187066973, 'support': 3213}, '2': {'precision': 0.8588427007748124, 'recall': 0.8791980107645337, 'f1-score': 0.868901158721518, 'support': 31771}, '3': {'precision': 0.859427183483453, 'recall': 0.8687468030690537, 'f1-score': 0.864061864061864, 'support': 9775}, '4': {'precision': 0.757518051257637, 'recall': 0.8076304881143728, 'f1-score': 0.7817720275139206, 'support': 11821}, 'accuracy': 0.8512096210320235, 'macro avg': {'precision': 0.7623968817806868, 'recall': 0.7265062044433872, 'f1-score': 0.730786432278676, 'support': 78661}, 'weighted avg': {'precision': 0.8403901614922495, 'recall': 0.8512096210320235, 'f1-score': 0.8428529574473348, 'support': 78661}}\n",
      "epoch 4 :finished\n",
      "train_loss: 0.40584629599245436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 4/150 [43:23<26:23:24, 650.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.409083832352142\n",
      "{'0': {'precision': 0.8989130434782608, 'recall': 0.9363253475838956, 'f1-score': 0.9172378607395577, 'support': 22081}, '1': {'precision': 0.39502018842530284, 'recall': 0.18269530034235917, 'f1-score': 0.24984039157267507, 'support': 3213}, '2': {'precision': 0.8585759123638378, 'recall': 0.8782222781782129, 'f1-score': 0.8682879770962673, 'support': 31771}, '3': {'precision': 0.8480039428289798, 'recall': 0.8801023017902814, 'f1-score': 0.8637550200803212, 'support': 9775}, '4': {'precision': 0.7885882761012833, 'recall': 0.7693088571186871, 'f1-score': 0.7788292724703464, 'support': 11821}, 'accuracy': 0.8499891941368658, 'macro avg': {'precision': 0.757820272639533, 'recall': 0.7293308170026873, 'f1-score': 0.7355901043918335, 'support': 78661}, 'weighted avg': {'precision': 0.8391331745478954, 'recall': 0.8499891941368658, 'f1-score': 0.8427605783373692, 'support': 78661}}\n",
      "epoch 5 :finished\n",
      "train_loss: 0.40293707227449893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 5/150 [54:14<26:12:45, 650.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.40245411515962787\n",
      "{'0': {'precision': 0.9186334007642166, 'recall': 0.9254562746252434, 'f1-score': 0.9220322158552542, 'support': 22081}, '1': {'precision': 0.41455160744500846, 'recall': 0.15250544662309368, 'f1-score': 0.22298065984072812, 'support': 3213}, '2': {'precision': 0.8591173766472572, 'recall': 0.8823455352365365, 'f1-score': 0.8705765438424868, 'support': 31771}, '3': {'precision': 0.8724047991653625, 'recall': 0.8554475703324809, 'f1-score': 0.8638429752066116, 'support': 9775}, '4': {'precision': 0.7429910131346493, 'recall': 0.8182894848151595, 'f1-score': 0.7788244766505635, 'support': 11821}, 'accuracy': 0.8516672811177076, 'macro avg': {'precision': 0.7615396394312989, 'recall': 0.7268088623265028, 'f1-score': 0.7316513742791289, 'support': 78661}, 'weighted avg': {'precision': 0.8418653499009877, 'recall': 0.8516672811177076, 'f1-score': 0.8439438452844322, 'support': 78661}}\n",
      "epoch 6 :finished\n",
      "train_loss: 0.4002748849276198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 6/150 [1:05:04<26:01:41, 650.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.4009831703533002\n",
      "{'0': {'precision': 0.917702490464438, 'recall': 0.9261808794891536, 'f1-score': 0.9219221926700626, 'support': 22081}, '1': {'precision': 0.45261845386533667, 'recall': 0.11297852474323063, 'f1-score': 0.18082191780821918, 'support': 3213}, '2': {'precision': 0.8428457186861357, 'recall': 0.8956910389978282, 'f1-score': 0.8684652241584522, 'support': 31771}, '3': {'precision': 0.8486428009441385, 'recall': 0.8827621483375959, 'f1-score': 0.8653662939377225, 'support': 9775}, '4': {'precision': 0.7852787082367088, 'recall': 0.7734540225023264, 'f1-score': 0.7793215138083874, 'support': 11821}, 'accuracy': 0.8523029201256023, 'macro avg': {'precision': 0.7694176344393515, 'recall': 0.7182133228140269, 'f1-score': 0.7231794284765687, 'support': 78661}, 'weighted avg': {'precision': 0.8399888903254076, 'recall': 0.8523029201256023, 'f1-score': 0.8416021730333181, 'support': 78661}}\n",
      "epoch 7 :finished\n",
      "train_loss: 0.3981709415236189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 7/150 [1:15:55<25:50:42, 650.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.40070115771235487\n",
      "{'0': {'precision': 0.911702033206073, 'recall': 0.9300756306326706, 'f1-score': 0.9207971842984286, 'support': 22081}, '1': {'precision': 0.43333333333333335, 'recall': 0.14970432617491441, 'f1-score': 0.22253065001156602, 'support': 3213}, '2': {'precision': 0.8594739106385594, 'recall': 0.8803311195744546, 'f1-score': 0.8697774944412483, 'support': 31771}, '3': {'precision': 0.8844827586206897, 'recall': 0.839693094629156, 'f1-score': 0.8615061663605352, 'support': 9775}, '4': {'precision': 0.740513519654624, 'recall': 0.827087386853904, 'f1-score': 0.7814098465473146, 'support': 11821}, 'accuracy': 0.8514003127343919, 'macro avg': {'precision': 0.7659011110906558, 'recall': 0.72537831157302, 'f1-score': 0.7312042683318185, 'support': 78661}, 'weighted avg': {'precision': 0.8419593889154157, 'recall': 0.8514003127343919, 'f1-score': 0.8433541774587624, 'support': 78661}}\n",
      "epoch 8 :finished\n",
      "train_loss: 0.3960271463635989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 8/150 [1:26:46<25:40:24, 650.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.39698149878077393\n",
      "{'0': {'precision': 0.9249500272578594, 'recall': 0.9220596893256646, 'f1-score': 0.9235025967840701, 'support': 22081}, '1': {'precision': 0.4250182882223848, 'recall': 0.18082788671023964, 'f1-score': 0.25371179039301306, 'support': 3213}, '2': {'precision': 0.8542643632953136, 'recall': 0.8887350099147021, 'f1-score': 0.8711588300629397, 'support': 31771}, '3': {'precision': 0.8743860382485108, 'recall': 0.8559590792838875, 'f1-score': 0.8650744416873449, 'support': 9775}, '4': {'precision': 0.762085308056872, 'recall': 0.8161746045173843, 'f1-score': 0.788203096278747, 'support': 11821}, 'accuracy': 0.8541971243691283, 'macro avg': {'precision': 0.7681408050161881, 'recall': 0.7327512539503755, 'f1-score': 0.7403301510412229, 'support': 78661}, 'weighted avg': {'precision': 0.8452215500516673, 'recall': 0.8541971243691283, 'f1-score': 0.8474094593338035, 'support': 78661}}\n",
      "epoch 9 :finished\n",
      "train_loss: 0.3946268266857295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 9/150 [1:37:37<25:29:25, 650.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.3960247411112475\n",
      "{'0': {'precision': 0.9265014125580971, 'recall': 0.9208369186178162, 'f1-score': 0.9236604810684352, 'support': 22081}, '1': {'precision': 0.43704474505723206, 'recall': 0.13071895424836602, 'f1-score': 0.20124580737901293, 'support': 3213}, '2': {'precision': 0.8508300561376122, 'recall': 0.892071385855025, 'f1-score': 0.870962785409176, 'support': 31771}, '3': {'precision': 0.8795411089866156, 'recall': 0.8470588235294118, 'f1-score': 0.8629944238886863, 'support': 9775}, '4': {'precision': 0.7514007214674956, 'recall': 0.8281871246087471, 'f1-score': 0.7879275653923541, 'support': 11821}, 'accuracy': 0.8538538793048652, 'macro avg': {'precision': 0.7690636088414106, 'recall': 0.7237746413718733, 'f1-score': 0.729358212627533, 'support': 78661}, 'weighted avg': {'precision': 0.8437961180117688, 'recall': 0.8538538793048652, 'f1-score': 0.8449316784789254, 'support': 78661}}\n",
      "epoch 10 :finished\n",
      "train_loss: 0.39332021745650897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 10/150 [1:48:28<25:18:44, 650.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.39601476631028865\n",
      "{'0': {'precision': 0.9257333150859905, 'recall': 0.9190254064580409, 'f1-score': 0.9223671651288577, 'support': 22081}, '1': {'precision': 0.417817679558011, 'recall': 0.1882975412387177, 'f1-score': 0.25960094400343275, 'support': 3213}, '2': {'precision': 0.8472934135284881, 'recall': 0.900097573258632, 'f1-score': 0.8728976526968041, 'support': 31771}, '3': {'precision': 0.8779765054503123, 'recall': 0.8486956521739131, 'f1-score': 0.8630878069080316, 'support': 9775}, '4': {'precision': 0.7777042672841548, 'recall': 0.7955333728110989, 'f1-score': 0.7865177936687157, 'support': 11821}, 'accuracy': 0.8542352627096019, 'macro avg': {'precision': 0.7693050361813913, 'recall': 0.7303299091880806, 'f1-score': 0.7408942724811683, 'support': 78661}, 'weighted avg': {'precision': 0.8451251199500391, 'recall': 0.8542352627096019, 'f1-score': 0.8475334496333303, 'support': 78661}}\n",
      "epoch 11 :finished\n",
      "train_loss: 0.39216715688988113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 11/150 [1:59:19<25:08:11, 651.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.4001922445205169\n",
      "{'0': {'precision': 0.9135274735061003, 'recall': 0.9291245867487885, 'f1-score': 0.9212600193089203, 'support': 22081}, '1': {'precision': 0.4142746314972847, 'recall': 0.16619981325863678, 'f1-score': 0.23722789871168368, 'support': 3213}, '2': {'precision': 0.8384775167490711, 'recall': 0.9020805136759938, 'f1-score': 0.8691169335274139, 'support': 31771}, '3': {'precision': 0.8664341403364793, 'recall': 0.8640409207161125, 'f1-score': 0.8652358756338677, 'support': 9775}, '4': {'precision': 0.8067364588074647, 'recall': 0.7496827679553337, 'f1-score': 0.7771639042357275, 'support': 11821}, 'accuracy': 0.851985100621655, 'macro avg': {'precision': 0.76789004417928, 'recall': 0.7222257204709731, 'f1-score': 0.7340009262835226, 'support': 78661}, 'weighted avg': {'precision': 0.8409219196231403, 'recall': 0.851985100621655, 'f1-score': 0.843643038053317, 'support': 78661}}\n",
      "epoch 12 :finished\n",
      "train_loss: 0.3907564521055447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 12/150 [2:10:11<24:57:43, 651.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.3938681259266729\n",
      "{'0': {'precision': 0.9264284088322331, 'recall': 0.9215615234817264, 'f1-score': 0.9239885574172456, 'support': 22081}, '1': {'precision': 0.43609022556390975, 'recall': 0.16246498599439776, 'f1-score': 0.23673469387755103, 'support': 3213}, '2': {'precision': 0.8504658896845133, 'recall': 0.8934562966227062, 'f1-score': 0.871431202799779, 'support': 31771}, '3': {'precision': 0.8669894910364723, 'recall': 0.8608695652173913, 'f1-score': 0.8639186900056465, 'support': 9775}, '4': {'precision': 0.7694909793814433, 'recall': 0.8082226545977498, 'f1-score': 0.7883814003383257, 'support': 11821}, 'accuracy': 0.8546293588944966, 'macro avg': {'precision': 0.7698929988997143, 'recall': 0.7293150051827944, 'f1-score': 0.7368909088877096, 'support': 78661}, 'weighted avg': {'precision': 0.8447483570445026, 'recall': 0.8546293588944966, 'f1-score': 0.846845608117302, 'support': 78661}}\n",
      "epoch 13 :finished\n",
      "train_loss: 0.3896956614930404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▊         | 13/150 [2:21:03<24:47:16, 651.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.3907247167656092\n",
      "{'0': {'precision': 0.9238043527442197, 'recall': 0.9246410941533445, 'f1-score': 0.9242225340636457, 'support': 22081}, '1': {'precision': 0.4031563845050215, 'recall': 0.17491441020852785, 'f1-score': 0.24397655741263294, 'support': 3213}, '2': {'precision': 0.8468604170358557, 'recall': 0.9024896918573542, 'f1-score': 0.8737905499093389, 'support': 31771}, '3': {'precision': 0.8831571077646053, 'recall': 0.8459335038363172, 'f1-score': 0.8641446337130315, 'support': 9775}, '4': {'precision': 0.7839263290079531, 'recall': 0.7921495643346587, 'f1-score': 0.7880164941513086, 'support': 11821}, 'accuracy': 0.8553794129238123, 'macro avg': {'precision': 0.7681809182115311, 'recall': 0.7280256528780404, 'f1-score': 0.7388301538499915, 'support': 78661}, 'weighted avg': {'precision': 0.8453887129531528, 'recall': 0.8553794129238123, 'f1-score': 0.8481332653628006, 'support': 78661}}\n",
      "epoch 14 :finished\n",
      "train_loss: 0.38875283396517774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 14/150 [2:31:53<24:36:01, 651.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.39834832979169316\n",
      "{'0': {'precision': 0.9308488612836439, 'recall': 0.9162628504143834, 'f1-score': 0.9234982654737995, 'support': 22081}, '1': {'precision': 0.4518430439952438, 'recall': 0.11826953003423592, 'f1-score': 0.18746916625555007, 'support': 3213}, '2': {'precision': 0.8366045428072219, 'recall': 0.9042523055616758, 'f1-score': 0.8691140657379255, 'support': 31771}, '3': {'precision': 0.8665498763396537, 'recall': 0.8602557544757033, 'f1-score': 0.863391344524873, 'support': 9775}, '4': {'precision': 0.7762644298646292, 'recall': 0.7907114457321716, 'f1-score': 0.7834213393680328, 'support': 11821}, 'accuracy': 0.8529894102541284, 'macro avg': {'precision': 0.7724221508580784, 'recall': 0.717950377243634, 'f1-score': 0.7253788362720363, 'support': 78661}, 'weighted avg': {'precision': 0.841997371029341, 'recall': 0.8529894102541284, 'f1-score': 0.8429488648639838, 'support': 78661}}\n",
      "epoch 15 :finished\n",
      "train_loss: 0.3879206508419609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 15/150 [2:42:44<24:24:50, 651.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.3908348328698941\n",
      "{'0': {'precision': 0.9256232120964446, 'recall': 0.9231918844255242, 'f1-score': 0.9244059495737349, 'support': 22081}, '1': {'precision': 0.4450600184672207, 'recall': 0.15001556178026768, 'f1-score': 0.22439478584729983, 'support': 3213}, '2': {'precision': 0.8507239439990427, 'recall': 0.8950930093481477, 'f1-score': 0.872344667863004, 'support': 31771}, '3': {'precision': 0.8609518060167018, 'recall': 0.8753964194373401, 'f1-score': 0.8681140306381251, 'support': 9775}, '4': {'precision': 0.7746143747948802, 'recall': 0.7986633956518061, 'f1-score': 0.7864550793452455, 'support': 11821}, 'accuracy': 0.8556082429666544, 'macro avg': {'precision': 0.771394671074858, 'recall': 0.7284720541286172, 'f1-score': 0.7351429026534819, 'support': 78661}, 'weighted avg': {'precision': 0.8450125836017073, 'recall': 0.8556082429666544, 'f1-score': 0.8470595441777796, 'support': 78661}}\n",
      "epoch 16 :finished\n",
      "train_loss: 0.38663743164567466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 16/150 [2:53:35<24:13:59, 651.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.39434635137639396\n",
      "{'0': {'precision': 0.9323398187755852, 'recall': 0.91798378696617, 'f1-score': 0.9251061110857559, 'support': 22081}, '1': {'precision': 0.42436974789915966, 'recall': 0.15717398070339247, 'f1-score': 0.22938905291846473, 'support': 3213}, '2': {'precision': 0.8309867199771527, 'recall': 0.9158351956186459, 'f1-score': 0.8713502829934417, 'support': 31771}, '3': {'precision': 0.8933481152993348, 'recall': 0.8243478260869566, 'f1-score': 0.8574620909816439, 'support': 9775}, '4': {'precision': 0.7871740059854638, 'recall': 0.7787835208527197, 'f1-score': 0.7829562850824969, 'support': 11821}, 'accuracy': 0.8534852086802863, 'macro avg': {'precision': 0.7736436815873393, 'recall': 0.718824862045577, 'f1-score': 0.7332527646123607, 'support': 78661}, 'weighted avg': {'precision': 0.8439943093856291, 'recall': 0.8534852086802863, 'f1-score': 0.8452089738523793, 'support': 78661}}\n",
      "epoch 17 :finished\n",
      "train_loss: 0.38604608096237575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█▏        | 17/150 [3:04:26<24:03:17, 651.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.3897338696490458\n",
      "{'0': {'precision': 0.9147934251443802, 'recall': 0.9325664598523618, 'f1-score': 0.9235944473099952, 'support': 22081}, '1': {'precision': 0.4320524835988753, 'recall': 0.14347961406784937, 'f1-score': 0.21542056074766358, 'support': 3213}, '2': {'precision': 0.8504720363288719, 'recall': 0.8960057914450285, 'f1-score': 0.8726453412626642, 'support': 31771}, '3': {'precision': 0.8797461660497091, 'recall': 0.8509462915601023, 'f1-score': 0.8651066042641705, 'support': 9775}, '4': {'precision': 0.7800444188533355, 'recall': 0.8022163945520684, 'f1-score': 0.7909750604720994, 'support': 11821}, 'accuracy': 0.8558370730094964, 'macro avg': {'precision': 0.7714217059950345, 'recall': 0.7250429102954821, 'f1-score': 0.7335484028113186, 'support': 78661}, 'weighted avg': {'precision': 0.8444910332314873, 'recall': 0.8558370730094964, 'f1-score': 0.8468921528649941, 'support': 78661}}\n",
      "epoch 18 :finished\n",
      "train_loss: 0.38506517994524536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 18/150 [3:15:17<23:52:12, 651.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.3932371474136182\n",
      "{'0': {'precision': 0.9157857174717873, 'recall': 0.9298039038087044, 'f1-score': 0.9227415730337079, 'support': 22081}, '1': {'precision': 0.43029259896729777, 'recall': 0.1556178026766262, 'f1-score': 0.2285714285714286, 'support': 3213}, '2': {'precision': 0.8489827622262719, 'recall': 0.8944635044537471, 'f1-score': 0.871129912329103, 'support': 31771}, '3': {'precision': 0.855878257409986, 'recall': 0.880306905370844, 'f1-score': 0.8679207221745927, 'support': 9775}, '4': {'precision': 0.7976283216480567, 'recall': 0.7795448777599188, 'f1-score': 0.7884829297510054, 'support': 11821}, 'accuracy': 0.855176008441286, 'macro avg': {'precision': 0.7697135315446799, 'recall': 0.7279473988139682, 'f1-score': 0.7357693131719675, 'support': 78661}, 'weighted avg': {'precision': 0.8437726477295184, 'recall': 0.855176008441286, 'f1-score': 0.8465530172589787, 'support': 78661}}\n",
      "epoch 19 :finished\n",
      "train_loss: 0.384982606526407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 19/150 [3:26:08<23:41:03, 650.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.3903719128389669\n",
      "{'0': {'precision': 0.9252217420968842, 'recall': 0.9211992210497713, 'f1-score': 0.9232060999409976, 'support': 22081}, '1': {'precision': 0.4245709123757904, 'recall': 0.14628073451602863, 'f1-score': 0.21759259259259262, 'support': 3213}, '2': {'precision': 0.8533669730281732, 'recall': 0.894274652985427, 'f1-score': 0.8733420425728118, 'support': 31771}, '3': {'precision': 0.8849453141754235, 'recall': 0.8442966751918158, 'f1-score': 0.8641432385738967, 'support': 9775}, '4': {'precision': 0.7548073210286509, 'recall': 0.8268336012181711, 'f1-score': 0.7891804602341542, 'support': 11821}, 'accuracy': 0.854934465618286, 'macro avg': {'precision': 0.7685824525409845, 'recall': 0.7265769769922427, 'f1-score': 0.7334928867828906, 'support': 78661}, 'weighted avg': {'precision': 0.8451355502310834, 'recall': 0.854934465618286, 'f1-score': 0.8467638512714782, 'support': 78661}}\n",
      "epoch 20 :finished\n",
      "train_loss: 0.38412708393815864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 20/150 [3:36:59<23:30:20, 650.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.3906864533337151\n",
      "{'0': {'precision': 0.9350023180343069, 'recall': 0.9133644309587428, 'f1-score': 0.9240567226409474, 'support': 22081}, '1': {'precision': 0.4543630892678034, 'recall': 0.14098972922502334, 'f1-score': 0.2152019002375297, 'support': 3213}, '2': {'precision': 0.8454026707453379, 'recall': 0.9046614837430361, 'f1-score': 0.8740287977618635, 'support': 31771}, '3': {'precision': 0.8935794010387889, 'recall': 0.8272122762148337, 'f1-score': 0.8591160220994475, 'support': 9775}, '4': {'precision': 0.7561891622595233, 'recall': 0.8346163607139836, 'f1-score': 0.7934695190606402, 'support': 11821}, 'accuracy': 0.8557607963285491, 'macro avg': {'precision': 0.7769073282691521, 'recall': 0.7241688561711239, 'f1-score': 0.7331745923600856, 'support': 78661}, 'weighted avg': {'precision': 0.8471617926902417, 'recall': 0.8557607963285491, 'f1-score': 0.8472021895555361, 'support': 78661}}\n",
      "epoch 21 :finished\n",
      "train_loss: 0.383046556550412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 21/150 [3:47:49<23:19:13, 650.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.3931718745973052\n",
      "{'0': {'precision': 0.9198134361826172, 'recall': 0.9288528599248222, 'f1-score': 0.9243110480182067, 'support': 22081}, '1': {'precision': 0.4217171717171717, 'recall': 0.15592903828197946, 'f1-score': 0.22767552828902524, 'support': 3213}, '2': {'precision': 0.8342350638885692, 'recall': 0.912404393944163, 'f1-score': 0.8715705287211172, 'support': 31771}, '3': {'precision': 0.8927469135802469, 'recall': 0.8285421994884911, 'f1-score': 0.8594471268636918, 'support': 9775}, '4': {'precision': 0.8013210039630119, 'recall': 0.7697318331782421, 'f1-score': 0.7852088367276493, 'support': 11821}, 'accuracy': 0.8542606882699177, 'macro avg': {'precision': 0.7739667178663233, 'recall': 0.7190920649635396, 'f1-score': 0.733642613723938, 'support': 78661}, 'weighted avg': {'precision': 0.8437329380502795, 'recall': 0.8542606882699177, 'f1-score': 0.845589940577051, 'support': 78661}}\n",
      "epoch 22 :finished\n",
      "train_loss: 0.38322938669387396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▍        | 22/150 [3:58:40<23:08:16, 650.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.39329446036883486\n",
      "{'0': {'precision': 0.9450108562258095, 'recall': 0.9067071237715684, 'f1-score': 0.9254628238611413, 'support': 22081}, '1': {'precision': 0.42538461538461536, 'recall': 0.1721132897603486, 'f1-score': 0.24506979836029252, 'support': 3213}, '2': {'precision': 0.8298023805455892, 'recall': 0.9172201063863271, 'f1-score': 0.8713241340130664, 'support': 31771}, '3': {'precision': 0.8948641812383152, 'recall': 0.8324296675191816, 'f1-score': 0.8625185499258003, 'support': 9775}, '4': {'precision': 0.7841858910063524, 'recall': 0.7936722781490567, 'f1-score': 0.788900567584612, 'support': 11821}, 'accuracy': 0.8547310611357598, 'macro avg': {'precision': 0.7758495848801363, 'recall': 0.7244284931172965, 'f1-score': 0.7386551747489826, 'support': 78661}, 'weighted avg': {'precision': 0.8468536594634877, 'recall': 0.8547310611357598, 'f1-score': 0.8474606904626308, 'support': 78661}}\n",
      "epoch 23 :finished\n",
      "train_loss: 0.3821847971439189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 23/150 [4:09:31<22:57:42, 650.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.39600484798836516\n",
      "{'0': {'precision': 0.898296289890167, 'recall': 0.9408088401793397, 'f1-score': 0.9190612073351472, 'support': 22081}, '1': {'precision': 0.3951473136915078, 'recall': 0.21288515406162464, 'f1-score': 0.2766990291262136, 'support': 3213}, '2': {'precision': 0.8546481766820749, 'recall': 0.8903717226401435, 'f1-score': 0.8721442885771542, 'support': 31771}, '3': {'precision': 0.8892771347455777, 'recall': 0.8331457800511509, 'f1-score': 0.8602968362119051, 'support': 9775}, '4': {'precision': 0.798908807482463, 'recall': 0.7803908298790289, 'f1-score': 0.7895412529955494, 'support': 11821}, 'accuracy': 0.8532182402969706, 'macro avg': {'precision': 0.7672555444983581, 'recall': 0.7315204653622576, 'f1-score': 0.7435485228491938, 'support': 78661}, 'weighted avg': {'precision': 0.8440586939234184, 'recall': 0.8532182402969706, 'f1-score': 0.8471070723454627, 'support': 78661}}\n",
      "epoch 24 :finished\n",
      "train_loss: 0.38220728392158965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 24/150 [4:20:22<22:47:10, 651.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.3903939114353521\n",
      "{'0': {'precision': 0.918404798138036, 'recall': 0.9292604501607717, 'f1-score': 0.9238007338540846, 'support': 22081}, '1': {'precision': 0.4100069492703266, 'recall': 0.18362900715841893, 'f1-score': 0.2536543422184007, 'support': 3213}, '2': {'precision': 0.8476297634204838, 'recall': 0.9010418306002329, 'f1-score': 0.8735200781154644, 'support': 31771}, '3': {'precision': 0.8697975542082006, 'recall': 0.8658823529411764, 'f1-score': 0.8678355377832461, 'support': 9775}, '4': {'precision': 0.802303094233474, 'recall': 0.7721004991117503, 'f1-score': 0.786912100702677, 'support': 11821}, 'accuracy': 0.8559133496904437, 'macro avg': {'precision': 0.7696284318541042, 'recall': 0.7303828279944701, 'f1-score': 0.7411445585347745, 'support': 78661}, 'weighted avg': {'precision': 0.8455650177170744, 'recall': 0.8559133496904437, 'f1-score': 0.848593612232539, 'support': 78661}}\n",
      "epoch 25 :finished\n",
      "train_loss: 0.3818227498632317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 25/150 [4:31:14<22:36:25, 651.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.39293223571002\n",
      "{'0': {'precision': 0.915369563283821, 'recall': 0.9321588696164123, 'f1-score': 0.9236879305315592, 'support': 22081}, '1': {'precision': 0.4338051623646961, 'recall': 0.1621537503890445, 'f1-score': 0.23606705935659264, 'support': 3213}, '2': {'precision': 0.8455966787386273, 'recall': 0.9039375531144754, 'f1-score': 0.8737943834241032, 'support': 31771}, '3': {'precision': 0.9215427129640754, 'recall': 0.7846547314578005, 'f1-score': 0.8476074704387224, 'support': 9775}, '4': {'precision': 0.7644230769230769, 'recall': 0.8204889603248456, 'f1-score': 0.7914643600310091, 'support': 11821}, 'accuracy': 0.8541971243691283, 'macro avg': {'precision': 0.7761474388548594, 'recall': 0.7206787729805157, 'f1-score': 0.7345242407563972, 'support': 78661}, 'weighted avg': {'precision': 0.845601614590258, 'recall': 0.8541971243691283, 'f1-score': 0.84612477892491, 'support': 78661}}\n",
      "epoch 26 :finished\n",
      "train_loss: 0.3814271735837351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 26/150 [4:42:05<22:25:50, 651.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.38983581010403673\n",
      "{'0': {'precision': 0.9179704962002683, 'recall': 0.9299850550246819, 'f1-score': 0.9239387190389419, 'support': 22081}, '1': {'precision': 0.4040660736975858, 'recall': 0.19794584500466852, 'f1-score': 0.26571965740547315, 'support': 3213}, '2': {'precision': 0.8508607058683135, 'recall': 0.89767397941519, 'f1-score': 0.8736406800428856, 'support': 31771}, '3': {'precision': 0.8610915669916575, 'recall': 0.8764194373401535, 'f1-score': 0.8686878929223282, 'support': 9775}, '4': {'precision': 0.806471686372122, 'recall': 0.7674477624566449, 'f1-score': 0.7864759427828348, 'support': 11821}, 'accuracy': 0.8559514880309175, 'macro avg': {'precision': 0.7680921058259894, 'recall': 0.7338944158482679, 'f1-score': 0.7436925784384927, 'support': 78661}, 'weighted avg': {'precision': 0.8460499889332574, 'recall': 0.8559514880309175, 'f1-score': 0.8492142539878318, 'support': 78661}}\n",
      "epoch 27 :finished\n",
      "train_loss: 0.380669501974648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 27/150 [4:52:56<22:14:43, 651.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.38967019475814774\n",
      "{'0': {'precision': 0.9208009697840435, 'recall': 0.9288075721208279, 'f1-score': 0.9247869414258014, 'support': 22081}, '1': {'precision': 0.4227150537634409, 'recall': 0.19576719576719576, 'f1-score': 0.26760263773665177, 'support': 3213}, '2': {'precision': 0.86158755484643, 'recall': 0.8838248717383778, 'f1-score': 0.8725645567260184, 'support': 31771}, '3': {'precision': 0.8559152677857714, 'recall': 0.8763171355498721, 'f1-score': 0.8659960572208462, 'support': 9775}, '4': {'precision': 0.777335176001951, 'recall': 0.8088994162930379, 'f1-score': 0.7928032501450958, 'support': 11821}, 'accuracy': 0.8561548925134438, 'macro avg': {'precision': 0.7676708044363274, 'recall': 0.7387232382938622, 'f1-score': 0.7447506886508828, 'support': 78661}, 'weighted avg': {'precision': 0.8469170077254842, 'recall': 0.8561548925134438, 'f1-score': 0.8497109741766856, 'support': 78661}}\n",
      "epoch 28 :finished\n",
      "train_loss: 0.3797733878123784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▊        | 28/150 [5:03:46<22:03:30, 650.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.3913842066153278\n",
      "{'0': {'precision': 0.9354091372439997, 'recall': 0.9142701870386305, 'f1-score': 0.9247188695233951, 'support': 22081}, '1': {'precision': 0.41041666666666665, 'recall': 0.1839402427637722, 'f1-score': 0.2540296582849775, 'support': 3213}, '2': {'precision': 0.8463403098025305, 'recall': 0.901136256334393, 'f1-score': 0.8728791597432889, 'support': 31771}, '3': {'precision': 0.8671995081463265, 'recall': 0.8657800511508952, 'f1-score': 0.8664891983208765, 'support': 9775}, '4': {'precision': 0.7833554596747427, 'recall': 0.7986633956518061, 'f1-score': 0.7909353663134084, 'support': 11821}, 'accuracy': 0.8557353707682332, 'macro avg': {'precision': 0.7685442163068533, 'recall': 0.7327580265878995, 'f1-score': 0.7418104504371893, 'support': 78661}, 'weighted avg': {'precision': 0.8466639881665174, 'recall': 0.8557353707682332, 'f1-score': 0.8490451089230636, 'support': 78661}}\n",
      "epoch 29 :finished\n",
      "train_loss: 0.37931170615550625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 29/150 [5:14:37<21:52:27, 650.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.3920950814233563\n",
      "{'0': {'precision': 0.9010312852066904, 'recall': 0.9417145962592274, 'f1-score': 0.9209238468522332, 'support': 22081}, '1': {'precision': 0.46837146702557203, 'recall': 0.10830999066293184, 'f1-score': 0.17593528816986856, 'support': 3213}, '2': {'precision': 0.8620763752455796, 'recall': 0.8839192974725378, 'f1-score': 0.8728612056506131, 'support': 31771}, '3': {'precision': 0.8596702854845195, 'recall': 0.8748849104859335, 'f1-score': 0.8672108705572176, 'support': 9775}, '4': {'precision': 0.7760636570315037, 'recall': 0.8085610354453938, 'f1-score': 0.7919791191945976, 'support': 11821}, 'accuracy': 0.8560150519317069, 'macro avg': {'precision': 0.773442613998773, 'recall': 0.7234779660652049, 'f1-score': 0.725782066084906, 'support': 78661}, 'weighted avg': {'precision': 0.8437053098804996, 'recall': 0.8560150519317069, 'f1-score': 0.8450292309487004, 'support': 78661}}\n",
      "epoch 30 :finished\n",
      "train_loss: 0.3792054473571149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 30/150 [5:25:28<21:41:27, 650.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.3873438721870988\n",
      "{'0': {'precision': 0.9215139800413558, 'recall': 0.9283999818848784, 'f1-score': 0.924944164955896, 'support': 22081}, '1': {'precision': 0.44662095984329087, 'recall': 0.1419234360410831, 'f1-score': 0.2153991497401984, 'support': 3213}, '2': {'precision': 0.8586200640986877, 'recall': 0.8938339995593466, 'f1-score': 0.8758732361785797, 'support': 31771}, '3': {'precision': 0.8747136013330556, 'recall': 0.85923273657289, 'f1-score': 0.8669040615162307, 'support': 9775}, '4': {'precision': 0.7666299732662368, 'recall': 0.824803316132307, 'f1-score': 0.7946534088593669, 'support': 11821}, 'accuracy': 0.8581507989982329, 'macro avg': {'precision': 0.7736197157165254, 'recall': 0.729638694038101, 'f1-score': 0.7355548042500543, 'support': 78661}, 'weighted avg': {'precision': 0.8476223256856623, 'recall': 0.8581507989982329, 'f1-score': 0.8493500376118254, 'support': 78661}}\n",
      "epoch 31 :finished\n",
      "train_loss: 0.37920300573342275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 31/150 [5:36:19<21:30:48, 650.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.3913166891389746\n",
      "{'0': {'precision': 0.9146379317990333, 'recall': 0.9341062451881709, 'f1-score': 0.9242695823624305, 'support': 22081}, '1': {'precision': 0.4522144522144522, 'recall': 0.12075941487706193, 'f1-score': 0.1906165561287153, 'support': 3213}, '2': {'precision': 0.8433242105882699, 'recall': 0.9019860879418338, 'f1-score': 0.8716693028348947, 'support': 31771}, '3': {'precision': 0.8681025641025641, 'recall': 0.8658823529411764, 'f1-score': 0.8669910371318822, 'support': 9775}, '4': {'precision': 0.7925527297977606, 'recall': 0.7724388799593943, 'f1-score': 0.7823665495673034, 'support': 11821}, 'accuracy': 0.8551378701008123, 'macro avg': {'precision': 0.7741663777004161, 'recall': 0.7190345961815275, 'f1-score': 0.7271826056050452, 'support': 78661}, 'weighted avg': {'precision': 0.8428167336375245, 'recall': 0.8551378701008123, 'f1-score': 0.8446148082754232, 'support': 78661}}\n",
      "epoch 32 :finished\n",
      "train_loss: 0.378637843298731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██▏       | 32/150 [5:47:09<21:19:51, 650.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.38810210470261614\n",
      "{'0': {'precision': 0.9308639714298795, 'recall': 0.9207463430098275, 'f1-score': 0.9257775146851235, 'support': 22081}, '1': {'precision': 0.4498539435248296, 'recall': 0.1437908496732026, 'f1-score': 0.2179245283018868, 'support': 3213}, '2': {'precision': 0.8612888412674116, 'recall': 0.8855245349532592, 'f1-score': 0.8732385622943696, 'support': 31771}, '3': {'precision': 0.8673216132368149, 'recall': 0.858005115089514, 'f1-score': 0.8626382103368475, 'support': 9775}, '4': {'precision': 0.7457274483578541, 'recall': 0.8489975467388546, 'f1-score': 0.7940187507417223, 'support': 11821}, 'accuracy': 0.8562057436340753, 'macro avg': {'precision': 0.7710111635633579, 'recall': 0.7314128778929316, 'f1-score': 0.7347195132719899, 'support': 78661}, 'weighted avg': {'precision': 0.847397169957456, 'recall': 0.8562057436340753, 'f1-score': 0.8479974998081792, 'support': 78661}}\n",
      "epoch 33 :finished\n",
      "train_loss: 0.3780446911732126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 33/150 [5:58:01<21:09:17, 650.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.38998502015582914\n",
      "{'0': {'precision': 0.915616511555417, 'recall': 0.9312078257325302, 'f1-score': 0.9233463559207867, 'support': 22081}, '1': {'precision': 0.41139240506329117, 'recall': 0.16184251478369124, 'f1-score': 0.23229841411659594, 'support': 3213}, '2': {'precision': 0.8608337685478172, 'recall': 0.8819678322998962, 'f1-score': 0.8712726594322315, 'support': 31771}, '3': {'precision': 0.8482582168864397, 'recall': 0.881841432225064, 'f1-score': 0.8647238802227015, 'support': 9775}, '4': {'precision': 0.7808947411466427, 'recall': 0.8077150833262837, 'f1-score': 0.7940785096473719, 'support': 11821}, 'accuracy': 0.8552014340016018, 'macro avg': {'precision': 0.7633991286399215, 'recall': 0.732914937673493, 'f1-score': 0.7371439638679375, 'support': 78661}, 'weighted avg': {'precision': 0.8442781359862656, 'recall': 0.8552014340016018, 'f1-score': 0.847376302668202, 'support': 78661}}\n",
      "epoch 34 :finished\n",
      "train_loss: 0.3779049778164856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 34/150 [6:08:52<20:58:33, 650.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.39049588592071843\n",
      "{'0': {'precision': 0.9241170352281464, 'recall': 0.9254562746252434, 'f1-score': 0.9247861700683351, 'support': 22081}, '1': {'precision': 0.3949671772428884, 'recall': 0.22471210706504824, 'f1-score': 0.28645110097202936, 'support': 3213}, '2': {'precision': 0.8443250858501364, 'recall': 0.9054483648610367, 'f1-score': 0.8738191427963913, 'support': 31771}, '3': {'precision': 0.8823340814363578, 'recall': 0.8446035805626598, 'f1-score': 0.8630566590006271, 'support': 9775}, '4': {'precision': 0.806234502302515, 'recall': 0.7701548092377971, 'f1-score': 0.7877817678362826, 'support': 11821}, 'accuracy': 0.8553667001436545, 'macro avg': {'precision': 0.7703955764120087, 'recall': 0.7340750272703571, 'f1-score': 0.7471789681347332, 'support': 78661}, 'weighted avg': {'precision': 0.8473681213772671, 'recall': 0.8553667001436545, 'f1-score': 0.8498674808839198, 'support': 78661}}\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(Transmodel.parameters(), lr=1e-4) ##for test of pretrained\n",
    "EPOCH = 150\n",
    "loss_list=[]\n",
    "los_min=10**10\n",
    "val_loss_list=[]\n",
    "ac_list=[]\n",
    "\n",
    "for epoch in tqdm.tqdm(range(EPOCH)):\n",
    "    running_loss = 0.0\n",
    "    count=0\n",
    "    for _, (inputs, labels) in enumerate(train_dataloader, 0):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        outputs = Transmodel(inputs)\n",
    "        loss = criterion(outputs, labels.squeeze())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        count=count+1\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    loss_loss=running_loss/count\n",
    "    loss_list.append(loss_loss)\n",
    "    print('epoch',epoch+1,':finished')\n",
    "    print('train_loss:',loss_loss)\n",
    "    with torch.no_grad():\n",
    "        count=0\n",
    "        running_loss=0.0\n",
    "        pre=list()\n",
    "        lab=list()\n",
    "        for _, (inputs, labels) in enumerate(test_dataloader, 0):\n",
    "            inputs=inputs.to(DEVICE)\n",
    "            labels=labels.to(DEVICE)\n",
    "            outputs = Transmodel(inputs)\n",
    "            loss =criterion(outputs, labels.squeeze())\n",
    "            running_loss += loss.item()\n",
    "            count+=1\n",
    "            _, predicted = torch.max(F.softmax(outputs).data, 1)\n",
    "            predicted=predicted.to('cpu')\n",
    "            labels=labels.to('cpu')\n",
    "            predicted=predicted.tolist()\n",
    "            labels=labels.tolist()\n",
    "            pre.append(predicted)\n",
    "            lab.append(labels)\n",
    "        loss_loss=running_loss/count\n",
    "        val_loss_list.append(loss_loss)\n",
    "        pre=sum(pre,[])\n",
    "        lab=sum(lab,[])\n",
    "        print('val_loss:',loss_loss)\n",
    "        cl = classification_report(lab, pre,output_dict=True)\n",
    "        print(cl)\n",
    "        ac_list.append(cl['accuracy'])\n",
    "#         if los_min>loss_loss:\n",
    "#             los_min=loss_loss\n",
    "#             torch.save(Transmodel.state_dict(),'Trans_8lay_state') \n",
    "\n",
    "#        torch.save(Transmodel.state_dict(),'PreTrain_Trans_8lay_nodrop_mulchan_eegspec_state')\n",
    "#        torch.save(Transmodel.state_dict(),'PreTest_Trans_8lay_50drop_noW_eegspec_state6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.2842285505784895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 1/2 [02:15<02:15, 135.72s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'precision': 0.9643047360451151, 'recall': 0.9388946225844336, 'f1-score': 0.9514300507724053, 'support': 196693}, '1': {'precision': 0.603467178292449, 'recall': 0.33340904788945674, 'f1-score': 0.4295154722134166, 'support': 26415}, '2': {'precision': 0.890987787309704, 'recall': 0.912200161441949, 'f1-score': 0.901469205125722, 'support': 301037}, '3': {'precision': 0.9026397564933343, 'recall': 0.875841274414967, 'f1-score': 0.8890386132046401, 'support': 97174}, '4': {'precision': 0.8108771465877725, 'recall': 0.9061449521628311, 'f1-score': 0.85586811461468, 'support': 108284}, 'accuracy': 0.8927005508475157, 'macro avg': {'precision': 0.834455320945675, 'recall': 0.7932980116987276, 'f1-score': 0.8054642911861727, 'support': 729603}, 'weighted avg': {'precision': 0.8900059403928737, 'recall': 0.8927005508475157, 'f1-score': 0.8894277139773409, 'support': 729603}}\n",
      "val_loss: 0.2842285505784895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [04:33<00:00, 136.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'precision': 0.9643047360451151, 'recall': 0.9388946225844336, 'f1-score': 0.9514300507724053, 'support': 196693}, '1': {'precision': 0.603467178292449, 'recall': 0.33340904788945674, 'f1-score': 0.4295154722134166, 'support': 26415}, '2': {'precision': 0.890987787309704, 'recall': 0.912200161441949, 'f1-score': 0.901469205125722, 'support': 301037}, '3': {'precision': 0.9026397564933343, 'recall': 0.875841274414967, 'f1-score': 0.8890386132046401, 'support': 97174}, '4': {'precision': 0.8108771465877725, 'recall': 0.9061449521628311, 'f1-score': 0.85586811461468, 'support': 108284}, 'accuracy': 0.8927005508475157, 'macro avg': {'precision': 0.834455320945675, 'recall': 0.7932980116987276, 'f1-score': 0.8054642911861727, 'support': 729603}, 'weighted avg': {'precision': 0.8900059403928737, 'recall': 0.8927005508475157, 'f1-score': 0.8894277139773409, 'support': 729603}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCH = 2\n",
    "loss_list=[]\n",
    "los_min=10**10\n",
    "val_loss_list=[]\n",
    "ac_list=[]\n",
    "\n",
    "for epoch in tqdm.tqdm(range(EPOCH)):\n",
    "    with torch.no_grad():\n",
    "        count=0\n",
    "        running_loss=0.0\n",
    "        pre=list()\n",
    "        lab=list()\n",
    "        for _, (inputs, labels) in enumerate(test_dataloader, 0):\n",
    "            inputs=inputs.to(DEVICE)\n",
    "            labels=labels.to(DEVICE)\n",
    "            outputs = Transmodel(inputs)\n",
    "            loss =criterion(outputs, labels.squeeze())\n",
    "            running_loss += loss.item()\n",
    "            count+=1\n",
    "            _, predicted = torch.max(F.softmax(outputs).data, 1)\n",
    "            predicted=predicted.to('cpu')\n",
    "            labels=labels.to('cpu')\n",
    "            predicted=predicted.tolist()\n",
    "            labels=labels.tolist()\n",
    "            pre.append(predicted)\n",
    "            lab.append(labels)\n",
    "        loss_loss=running_loss/count\n",
    "        val_loss_list.append(loss_loss)\n",
    "        pre=sum(pre,[])\n",
    "        lab=sum(lab,[])\n",
    "        print('val_loss:',loss_loss)\n",
    "        cl = classification_report(lab, pre,output_dict=True)\n",
    "        print(cl)\n",
    "        ac_list.append(cl['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
